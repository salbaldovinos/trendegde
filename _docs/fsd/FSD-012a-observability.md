# FSD-012a: Observability Setup

**TrendEdge -- AI-Powered Futures Trading Platform**

| Field | Value |
|---|---|
| FSD ID | FSD-012a |
| Source | PRD-012 |
| Title | Observability Setup |
| Version | 1.0 |
| Status | Draft |
| Author | Generated by Claude |
| Created | 2026-02-12 |

---

## Table of Contents

1. [Introduction](#1-introduction)
2. [Integration Specifications](#2-integration-specifications)
3. [Dashboard Specifications](#3-dashboard-specifications)
4. [Alerting Specifications](#4-alerting-specifications)
5. [Configuration Matrix](#5-configuration-matrix)
6. [Testing Specifications](#6-testing-specifications)
7. [Failure Modes](#7-failure-modes)
8. [Security Specifications](#8-security-specifications)

---

## 1. Introduction

### 1.1 Purpose

This sub-FSD specifies the external observability integrations for the TrendEdge platform: log shipping to Axiom and uptime monitoring via Uptime Robot. The application already emits structured JSON logs to stdout (via structlog) and exposes health check endpoints (`/health`, `/health/ready`, `/health/detailed`). This document covers the wiring of those outputs to external observability services -- account setup, log drain configuration, dashboard creation, alert rules, and verification procedures.

This is a configuration-focused specification. No new application code is required beyond verification scripts and minor log field additions.

### 1.2 Scope

This document covers:

- **Axiom log shipping**: Railway log drain configuration for backend services (API, Worker, Beat), Vercel Marketplace integration for the frontend, dataset provisioning, and ingestion verification.
- **Axiom dashboard**: Six monitoring panels with exact APL queries, visualization types, and threshold lines.
- **Axiom alerting**: Four alert rules with exact trigger conditions, notification channels, and severity levels.
- **Uptime Robot monitoring**: Four HTTP monitors (API Liveness, API Readiness, Frontend, Staging API) with check intervals and alert thresholds.
- **Uptime Robot status page**: Public status page configuration with component mapping.
- **Uptime Robot alert channels**: Email and Telegram notification setup.

### 1.3 Out of Scope

- Application-level logging implementation (already complete in `backend/app/core/logging.py` using structlog with JSON output).
- Health check endpoint implementation (already complete in `backend/app/api/v1/health.py` with liveness, readiness, and detailed endpoints).
- Sentry error tracking (already configured and operational).
- Custom APM or distributed tracing (not required at MVP scale).
- IBKR feed health monitoring in Axiom (deferred to FSD-012d when CS-FR-040+ is implemented).

### 1.4 External Dependencies

| Dependency | Type | Description |
|---|---|---|
| Axiom | Hard | Log aggregation SaaS. Free tier: 500MB/day ingest, 30-day retention. |
| Uptime Robot | Hard | External uptime monitoring SaaS. Free tier: 50 monitors, 5-minute checks. Paid plan required for 1-minute checks. |
| Railway | Hard | Backend hosting platform. Provides native log drain feature for forwarding stdout to external services. |
| Vercel | Hard | Frontend hosting platform. Provides Axiom integration via Vercel Marketplace. |
| Telegram Bot API | Soft | For Uptime Robot Telegram alert delivery. Requires a Telegram bot token and chat ID. |

---

## 2. Integration Specifications

### 2.1 Axiom Account & Dataset Setup

#### 2.1.1 Account Provisioning

1. Create an Axiom account at `https://app.axiom.co/register` using the TrendEdge operator email.
2. Select the **Free** plan (500MB/day, 30-day retention). Upgrade to Personal ($25/mo, 10GB/day) if ingestion exceeds the free tier.
3. Enable two-factor authentication on the Axiom account.

#### 2.1.2 Dataset Creation

Create two datasets:

| Dataset Name | Environment | Purpose |
|---|---|---|
| `trendedge-production` | Production | All production service logs (API, Worker, Beat, Frontend) |
| `trendedge-staging` | Staging | All staging service logs |

Dataset configuration:
- Retention: 30 days (free tier default).
- No custom field mappings required -- Axiom auto-parses JSON fields from structured log output.

#### 2.1.3 API Token Provisioning

Create two API tokens in Axiom (Settings > API Tokens):

| Token Name | Permissions | Used By |
|---|---|---|
| `railway-ingest` | Ingest only on `trendedge-production` and `trendedge-staging` | Railway log drain |
| `dashboard-readonly` | Query only on `trendedge-production` | Shared dashboard links (optional) |

The `railway-ingest` token is the only token required at minimum. The `dashboard-readonly` token is optional and used only if read-only dashboard sharing is needed outside of authenticated Axiom access.

### 2.2 Railway Log Drain Configuration

Railway's log drain feature forwards all stdout/stderr output from a service to an external HTTP endpoint. Since the TrendEdge backend already writes structured JSON to stdout via structlog, no log format changes are needed.

#### 2.2.1 Log Drain Setup Per Service

Configure a log drain on each of the three Railway services. In the Railway dashboard:

1. Navigate to the project > select the service.
2. Go to Settings > Log Drains.
3. Click "Add Log Drain".
4. Select "Axiom" as the drain type.
5. Enter the Axiom dataset name and API token.

| Railway Service | Axiom Dataset | Notes |
|---|---|---|
| `trendedge-api` | `trendedge-production` | FastAPI application server. Emits request logs, error logs, middleware timing. |
| `trendedge-worker` | `trendedge-production` | Celery worker. Emits task execution logs, broker adapter logs, detection pipeline logs. |
| `trendedge-beat` | `trendedge-production` | Celery Beat scheduler. Emits schedule tick logs and task dispatch logs. |

For staging, repeat the same configuration pointing to the `trendedge-staging` dataset.

#### 2.2.2 Structured Log Field Mapping

The application emits JSON logs via structlog with the following fields. Axiom auto-indexes all top-level JSON keys.

| Field | Type | Source | Example | Axiom Auto-Indexed |
|---|---|---|---|---|
| `timestamp` | string (ISO 8601) | structlog `TimeStamper` | `"2026-02-12T14:30:00.123456Z"` | Yes |
| `level` | string | structlog `add_log_level` | `"info"`, `"error"`, `"warning"` | Yes |
| `logger` | string | structlog `add_logger_name` | `"trendedge.api.v1.health"` | Yes |
| `event` | string | structlog (message field) | `"Request completed"` | Yes |
| `request_id` | string (UUID) | RequestID middleware via contextvars | `"a1b2c3d4-..."` | Yes |
| `user_id` | string (UUID) | Auth middleware via contextvars | `"u1v2w3x4-..."` | Yes |
| `duration_ms` | float | Timing middleware | `45.2` | Yes |
| `method` | string | Request logging middleware | `"GET"` | Yes |
| `path` | string | Request logging middleware | `"/api/v1/trendlines"` | Yes |
| `status_code` | int | Request logging middleware | `200` | Yes |
| `task_name` | string | Celery task logging | `"detect_trendlines"` | Yes |
| `task_id` | string (UUID) | Celery task logging | `"t1u2v3w4-..."` | Yes |

Railway adds additional metadata fields automatically:

| Railway Field | Description |
|---|---|
| `_railway_service` | Service name (e.g., `trendedge-api`) |
| `_railway_environment` | Environment name |
| `_railway_deployment_id` | Deployment identifier |

These Railway-injected fields are useful for filtering logs by service in Axiom queries.

#### 2.2.3 Ingestion Verification

After configuring each log drain, verify ingestion within 5 minutes:

1. Trigger a known API request: `curl https://api.trendedge.io/health`
2. In Axiom, navigate to the `trendedge-production` dataset.
3. Run the query: `| where path == "/health"` over the last 15 minutes.
4. Confirm the log entry appears with all expected structured fields.
5. Repeat for a worker log: trigger a Celery task (e.g., via a trendline detection scan) and query `| where logger =~ "trendedge.tasks"`.

### 2.3 Vercel Log Drain Configuration (Frontend)

#### 2.3.1 Axiom-Vercel Integration

Vercel provides a native Axiom integration through the Vercel Marketplace. This is the recommended method over manual log drain configuration.

Setup steps:

1. In the Vercel dashboard, navigate to the `trendedge-web` project.
2. Go to Settings > Integrations.
3. Search for "Axiom" in the Vercel Marketplace.
4. Click "Add Integration" and authorize the Axiom account.
5. In the integration settings, map the `trendedge-web` Vercel project to the `trendedge-production` Axiom dataset.
6. Enable forwarding for: **Serverless Function Logs**, **Edge Function Logs**, and **Build Logs** (build logs optional but useful for debugging deploy failures).

#### 2.3.2 Vercel Log Format

Vercel forwards logs with its own envelope format. The Axiom-Vercel integration normalizes these into queryable fields:

| Vercel Field | Axiom Field | Description |
|---|---|---|
| `message` | `message` | Log message body |
| `level` | `vercel.level` | `info`, `warn`, `error` |
| `source` | `vercel.source` | `server`, `edge`, `build` |
| `host` | `vercel.host` | Deployment hostname |
| `path` | `vercel.path` | Request path |
| `statusCode` | `vercel.statusCode` | HTTP response status |
| `region` | `vercel.region` | Edge region (e.g., `iad1`) |

#### 2.3.3 Frontend Ingestion Verification

1. Navigate to `https://app.trendedge.io` in a browser to trigger a server-side render.
2. In Axiom, query the `trendedge-production` dataset: `| where vercel.source == "server"` over the last 15 minutes.
3. Confirm at least one log entry appears from the Vercel integration.

### 2.4 Uptime Robot Account & Monitor Setup

#### 2.4.1 Account Provisioning

1. Create an Uptime Robot account at `https://uptimerobot.com/signUp` using the TrendEdge operator email.
2. Select the **Pro** plan ($7/mo) for 1-minute check intervals. The Free plan (5-minute intervals) is acceptable for staging but not production.
3. Enable two-factor authentication.

#### 2.4.2 Monitor Configuration

Create four HTTP(s) monitors:

**Monitor 1: API Liveness (Production)**

| Parameter | Value |
|---|---|
| Friendly Name | `TrendEdge API (Liveness)` |
| URL | `https://api.trendedge.io/health` |
| Monitor Type | HTTP(s) |
| HTTP Method | GET |
| Expected Status Code | 200 |
| Check Interval | 60 seconds |
| Timeout | 30 seconds |
| Alert Threshold | 1 failure (immediate alert) |
| Alert Contacts | All (Email + Telegram) |
| Keyword Monitoring | Contains `"status":"ok"` |

**Monitor 2: API Readiness (Production)**

| Parameter | Value |
|---|---|
| Friendly Name | `TrendEdge API (Readiness)` |
| URL | `https://api.trendedge.io/health/ready` |
| Monitor Type | HTTP(s) |
| HTTP Method | GET |
| Expected Status Code | 200 |
| Check Interval | 60 seconds |
| Timeout | 30 seconds |
| Alert Threshold | 2 consecutive failures |
| Alert Contacts | All (Email + Telegram) |
| Keyword Monitoring | Contains `"status":"ok"` |

The readiness endpoint checks database, Redis, and Celery connectivity. A 503 response with `"status":"degraded"` indicates a dependency is down but the API process is running. Using 2 consecutive failures avoids false alerts from transient dependency restarts.

**Monitor 3: Frontend (Production)**

| Parameter | Value |
|---|---|
| Friendly Name | `TrendEdge Frontend` |
| URL | `https://app.trendedge.io` |
| Monitor Type | HTTP(s) |
| HTTP Method | GET |
| Expected Status Code | 200 |
| Check Interval | 60 seconds |
| Timeout | 30 seconds |
| Alert Threshold | 2 consecutive failures |
| Alert Contacts | All (Email + Telegram) |

**Monitor 4: Staging API**

| Parameter | Value |
|---|---|
| Friendly Name | `TrendEdge Staging API` |
| URL | `https://staging-api.trendedge.io/health` |
| Monitor Type | HTTP(s) |
| HTTP Method | GET |
| Expected Status Code | 200 |
| Check Interval | 300 seconds |
| Timeout | 30 seconds |
| Alert Threshold | 3 consecutive failures |
| Alert Contacts | Email only |
| Keyword Monitoring | Contains `"status":"ok"` |

Staging uses a longer check interval (5 minutes) and higher failure threshold (3 consecutive) because staging downtime is lower urgency and the service may be intentionally restarted during deployments.

#### 2.4.3 Alert Contact Setup

**Email Contact:**

| Parameter | Value |
|---|---|
| Contact Name | `Operator Email` |
| Contact Type | Email |
| Email Address | TrendEdge operator email |
| Alert Types | Down, Up, SSL Expiry |

**Telegram Contact:**

| Parameter | Value |
|---|---|
| Contact Name | `Operator Telegram` |
| Contact Type | Telegram |
| Setup Method | Uptime Robot's built-in Telegram integration |
| Alert Types | Down, Up (production monitors only) |

Telegram setup steps:
1. In Uptime Robot, go to My Settings > Alert Contacts > Add Alert Contact.
2. Select Type: Telegram.
3. Click "Connect Telegram" -- this opens a link to start a conversation with the `@UptimeRobot_Bot` on Telegram.
4. Send `/start` to the bot from the operator's Telegram account.
5. The bot returns a confirmation code. Enter this code in the Uptime Robot alert contact form.
6. Save the contact and assign it to production monitors (Monitors 1, 2, and 3).

#### 2.4.4 Status Page Configuration

Create a public status page in Uptime Robot:

| Parameter | Value |
|---|---|
| Status Page Name | `TrendEdge Status` |
| Custom Domain | `status.trendedge.io` (CNAME to `stats.uptimerobot.com`) |
| Default URL | `https://stats.uptimerobot.com/trendedge` (fallback if custom domain is not configured) |
| Theme | Dark |
| Logo | TrendEdge logo URL |

**Status Page Components:**

| Component Name | Mapped Monitors | Description |
|---|---|---|
| API | `TrendEdge API (Liveness)` + `TrendEdge API (Readiness)` | Shows degraded if either monitor is down |
| Frontend | `TrendEdge Frontend` | Web application availability |
| Database | Inferred from `TrendEdge API (Readiness)` | The readiness endpoint checks database connectivity; if readiness fails and liveness succeeds, database is likely the issue |

The "Real-time Data Feed" component is deferred until IBKR live feed monitoring (CS-FR-042) is implemented.

DNS configuration for custom domain:
- Add a CNAME record: `status.trendedge.io` -> `stats.uptimerobot.com`
- In Uptime Robot, verify the custom domain ownership.

---

## 3. Dashboard Specifications

### 3.1 Axiom Dashboard Overview

Create a single Axiom dashboard named **"TrendEdge Operations"** with six panels arranged in a 3x2 grid.

Layout:
```
+-------------------------+-------------------------+-------------------------+
| Panel 1: Request Rate   | Panel 2: Error Rate     | Panel 3: p95 Latency    |
| (stacked bar)           | (line + threshold)      | (line + threshold)      |
+-------------------------+-------------------------+-------------------------+
| Panel 4: Slow Requests  | Panel 5: Error Log      | Panel 6: Worker Tasks   |
| (table)                 | (table)                 | (bar chart)             |
+-------------------------+-------------------------+-------------------------+
```

Default time range: Last 6 hours.
Auto-refresh interval: 1 minute.

### 3.2 Panel Specifications

#### Panel 1: Request Rate

| Property | Value |
|---|---|
| Title | Request Rate |
| Visualization | Stacked bar chart |
| Time bucket | 5 minutes |
| Dataset | `trendedge-production` |

**APL Query:**
```apl
['trendedge-production']
| where isnotnull(status_code)
| where _railway_service == "trendedge-api"
| summarize count() by bin(_time, 5m), tostring(status_code)
| order by _time asc
```

Group by `status_code` to produce stacked bars colored by HTTP status:
- 2xx: green
- 3xx: blue
- 4xx: yellow
- 5xx: red

#### Panel 2: Error Rate

| Property | Value |
|---|---|
| Title | Error Rate (5m buckets) |
| Visualization | Line chart |
| Time bucket | 5 minutes |
| Threshold line | 10 errors per 5 minutes (red dashed) |
| Dataset | `trendedge-production` |

**APL Query:**
```apl
['trendedge-production']
| where level == "error" or level == "critical"
| summarize error_count = count() by bin(_time, 5m)
| order by _time asc
```

The threshold line at 10 errors/5min provides a visual reference. The actual alerting threshold is higher (20 errors/5min) to avoid alert fatigue.

#### Panel 3: p95 Latency

| Property | Value |
|---|---|
| Title | API p95 Latency (ms) |
| Visualization | Line chart |
| Time bucket | 5 minutes |
| Threshold line | 200ms (yellow dashed) |
| Dataset | `trendedge-production` |

**APL Query:**
```apl
['trendedge-production']
| where isnotnull(duration_ms)
| where _railway_service == "trendedge-api"
| summarize p95 = percentile(duration_ms, 95) by bin(_time, 5m)
| order by _time asc
```

#### Panel 4: Slow Requests

| Property | Value |
|---|---|
| Title | Slow Requests (>1s) |
| Visualization | Table |
| Sort | `duration_ms` descending |
| Max rows | 50 |
| Dataset | `trendedge-production` |

**APL Query:**
```apl
['trendedge-production']
| where duration_ms > 1000
| where _railway_service == "trendedge-api"
| project _time, path, method, duration_ms, status_code, request_id, user_id
| order by duration_ms desc
| take 50
```

Table columns: Timestamp, Path, Method, Duration (ms), Status, Request ID, User ID.

#### Panel 5: Error Log

| Property | Value |
|---|---|
| Title | Error Log |
| Visualization | Table |
| Sort | `_time` descending |
| Max rows | 100 |
| Dataset | `trendedge-production` |

**APL Query:**
```apl
['trendedge-production']
| where level == "error" or level == "critical"
| project _time, _railway_service, logger, event, request_id, user_id
| order by _time desc
| take 100
```

Table columns: Timestamp, Service, Logger, Message, Request ID, User ID.

#### Panel 6: Worker Task Duration

| Property | Value |
|---|---|
| Title | Worker Task p95 Duration |
| Visualization | Bar chart |
| Group by | `task_name` |
| Dataset | `trendedge-production` |

**APL Query:**
```apl
['trendedge-production']
| where _railway_service == "trendedge-worker"
| where isnotnull(task_name)
| where isnotnull(duration_ms)
| summarize p95_duration = percentile(duration_ms, 95), task_count = count() by task_name
| order by p95_duration desc
```

Bar chart with task name on X-axis and p95 duration (ms) on Y-axis. Each bar also displays the task count as a label.

---

## 4. Alerting Specifications

### 4.1 Axiom Alert Rules

Axiom alerts are configured in the Axiom dashboard under Monitors > New Monitor. Each alert evaluates an APL query on a schedule and fires when the condition is met.

#### Alert 1: High Error Rate

| Property | Value |
|---|---|
| Monitor Name | `TrendEdge: High Error Rate` |
| Severity | Critical |
| Dataset | `trendedge-production` |
| Evaluation Window | 5 minutes |
| Evaluation Frequency | Every 1 minute |
| Notification Channels | Email + Telegram (via Axiom webhook to Telegram bot) |
| Resolve Notification | Yes (send "Resolved" when condition clears) |

**APL Query:**
```apl
['trendedge-production']
| where level == "error" or level == "critical"
| summarize error_count = count()
```

**Trigger condition:** `error_count > 20`

**Notification message template:**
```
[CRITICAL] TrendEdge: High Error Rate
{error_count} errors in the last 5 minutes (threshold: 20)
Dataset: trendedge-production
Dashboard: {dashboard_url}
```

#### Alert 2: Slow API

| Property | Value |
|---|---|
| Monitor Name | `TrendEdge: Slow API` |
| Severity | Warning |
| Dataset | `trendedge-production` |
| Evaluation Window | 10 minutes |
| Evaluation Frequency | Every 2 minutes |
| Notification Channels | Email |
| Resolve Notification | Yes |

**APL Query:**
```apl
['trendedge-production']
| where isnotnull(duration_ms)
| where _railway_service == "trendedge-api"
| summarize p95 = percentile(duration_ms, 95)
```

**Trigger condition:** `p95 > 2000` (2 seconds)

**Notification message template:**
```
[WARNING] TrendEdge: Slow API Response
p95 latency: {p95}ms over the last 10 minutes (threshold: 2000ms)
Dataset: trendedge-production
Dashboard: {dashboard_url}
```

#### Alert 3: Worker Failures

| Property | Value |
|---|---|
| Monitor Name | `TrendEdge: Worker Failures` |
| Severity | Critical |
| Dataset | `trendedge-production` |
| Evaluation Window | 15 minutes |
| Evaluation Frequency | Every 5 minutes |
| Notification Channels | Email + Telegram |
| Resolve Notification | Yes |

**APL Query:**
```apl
['trendedge-production']
| where _railway_service == "trendedge-worker"
| where level == "error" or level == "critical"
| summarize failure_count = count()
```

**Trigger condition:** `failure_count > 5`

**Notification message template:**
```
[CRITICAL] TrendEdge: Worker Failures
{failure_count} task failures in the last 15 minutes (threshold: 5)
Dataset: trendedge-production
Dashboard: {dashboard_url}
```

#### Alert 4: Zero Traffic

| Property | Value |
|---|---|
| Monitor Name | `TrendEdge: Zero Traffic` |
| Severity | Warning |
| Dataset | `trendedge-production` |
| Evaluation Window | 10 minutes |
| Evaluation Frequency | Every 5 minutes |
| Notification Channels | Email |
| Resolve Notification | Yes |

**APL Query:**
```apl
['trendedge-production']
| where _railway_service == "trendedge-api"
| where isnotnull(status_code)
| summarize request_count = count()
```

**Trigger condition:** `request_count == 0`

**Schedule restriction:** This alert should only fire during US market hours (Monday-Friday, 08:00-18:00 ET / 13:00-23:00 UTC). Outside market hours, zero traffic is expected and the alert is muted.

If Axiom does not support time-of-day muting natively, implement this by adding a condition to the query that filters on the current hour:

```apl
['trendedge-production']
| where _railway_service == "trendedge-api"
| where isnotnull(status_code)
| where hourofday(now()) >= 13 and hourofday(now()) <= 23
| where dayofweek(now()) >= 1 and dayofweek(now()) <= 5
| summarize request_count = count()
```

If the time filter approach is not supported, accept that this alert may fire outside market hours and manually mute it during off-hours periods using Axiom's snooze/mute feature.

### 4.2 Axiom Telegram Notification Channel

Axiom does not natively integrate with Telegram. To deliver alerts to Telegram, use an Axiom webhook notification channel that posts to a Telegram Bot API endpoint.

Setup:

1. Create a Telegram bot via `@BotFather` (or reuse the existing TrendEdge notification bot from PRD-010 if already created).
2. Get the bot token and the operator's chat ID.
3. In Axiom, go to Monitors > Notification Channels > Add Channel.
4. Select Type: Webhook.
5. Configure the webhook URL: `https://api.telegram.org/bot{BOT_TOKEN}/sendMessage`
6. HTTP Method: POST
7. Content-Type: `application/json`
8. Body template:
```json
{
  "chat_id": "{OPERATOR_CHAT_ID}",
  "text": "{{.MonitorName}}\n{{.Description}}",
  "parse_mode": "Markdown"
}
```

Replace `{BOT_TOKEN}` and `{OPERATOR_CHAT_ID}` with actual values during setup. These values are entered directly in the Axiom webhook configuration UI -- they are not stored in application environment variables.

### 4.3 Escalation Behavior

| Scenario | Behavior |
|---|---|
| Alert fires, then resolves within 5 minutes | Initial alert + resolve notification sent. No escalation. |
| Alert fires and remains active for >30 minutes | Axiom re-sends the alert notification every 30 minutes until resolved (default re-notification interval). |
| Multiple alerts fire simultaneously | Each alert sends independently. No deduplication across alerts. |
| Axiom notification channel fails (e.g., Telegram webhook error) | Axiom logs the delivery failure. Email channel serves as fallback since both channels are configured on Critical alerts. |

---

## 5. Configuration Matrix

### 5.1 Environment Variables

All observability-related environment variables are set in external service dashboards. None are set in application code or `.env` files.

#### Railway Environment Variables

| Variable | Set Where | Value | Used By | Required |
|---|---|---|---|---|
| *(none)* | -- | -- | -- | -- |

Railway log drains are configured in the Railway dashboard UI, not via environment variables. The Axiom API token is entered directly into the Railway log drain configuration form. It does not need to be an environment variable accessible to the application process.

#### Vercel Environment Variables

| Variable | Set Where | Value | Used By | Required |
|---|---|---|---|---|
| *(none)* | -- | -- | -- | -- |

The Axiom-Vercel integration is configured through the Vercel Marketplace integration UI. No environment variables are required.

#### Axiom Configuration (in Axiom Dashboard)

| Setting | Value | Location |
|---|---|---|
| Dataset: `trendedge-production` | Created in Axiom Datasets | Axiom > Datasets > New Dataset |
| Dataset: `trendedge-staging` | Created in Axiom Datasets | Axiom > Datasets > New Dataset |
| API Token: `railway-ingest` | Ingest-only, both datasets | Axiom > Settings > API Tokens |
| API Token: `dashboard-readonly` | Query-only, production dataset | Axiom > Settings > API Tokens |
| Dashboard: `TrendEdge Operations` | 6 panels (see Section 3) | Axiom > Dashboards > New Dashboard |
| Monitors: 4 alert rules | See Section 4 | Axiom > Monitors > New Monitor |
| Notification Channel: Email | Operator email | Axiom > Monitors > Notification Channels |
| Notification Channel: Telegram Webhook | Bot API URL + chat ID | Axiom > Monitors > Notification Channels |

#### Uptime Robot Configuration (in Uptime Robot Dashboard)

| Setting | Value | Location |
|---|---|---|
| Monitor: API Liveness | `https://api.trendedge.io/health`, 60s interval | Uptime Robot > Monitors |
| Monitor: API Readiness | `https://api.trendedge.io/health/ready`, 60s interval | Uptime Robot > Monitors |
| Monitor: Frontend | `https://app.trendedge.io`, 60s interval | Uptime Robot > Monitors |
| Monitor: Staging API | `https://staging-api.trendedge.io/health`, 300s interval | Uptime Robot > Monitors |
| Alert Contact: Email | Operator email | Uptime Robot > Alert Contacts |
| Alert Contact: Telegram | Via `@UptimeRobot_Bot` | Uptime Robot > Alert Contacts |
| Status Page | `status.trendedge.io` or hosted URL | Uptime Robot > Status Pages |

#### DNS Configuration

| Record | Type | Name | Value | Purpose |
|---|---|---|---|---|
| CNAME | CNAME | `status.trendedge.io` | `stats.uptimerobot.com` | Uptime Robot status page custom domain |

### 5.2 Naming Conventions

| Resource Type | Convention | Examples |
|---|---|---|
| Axiom datasets | `trendedge-{environment}` | `trendedge-production`, `trendedge-staging` |
| Axiom API tokens | `{purpose}` descriptor | `railway-ingest`, `dashboard-readonly` |
| Axiom monitors | `TrendEdge: {description}` | `TrendEdge: High Error Rate` |
| Uptime Robot monitors | `TrendEdge {Component} ({Context})` | `TrendEdge API (Liveness)` |
| Uptime Robot alert contacts | `Operator {Channel}` | `Operator Email`, `Operator Telegram` |

---

## 6. Testing Specifications

### 6.1 Axiom Log Shipping Verification

| Test ID | Test Case | Steps | Expected Outcome |
|---|---|---|---|
| OBS-T-001 | API request log appears in Axiom | 1. Send `GET https://api.trendedge.io/health` 2. Wait 10 seconds 3. In Axiom, query: `\| where path == "/health"` over last 15 minutes | Log entry found with fields: `timestamp`, `level`, `logger`, `path`, `status_code`, `duration_ms` |
| OBS-T-002 | Worker task log appears in Axiom | 1. Trigger a Celery task (e.g., trendline detection scan via API or Beat schedule) 2. Wait 10 seconds 3. In Axiom, query: `\| where _railway_service == "trendedge-worker" \| where isnotnull(task_name)` | Log entry found with `task_name` and `duration_ms` fields |
| OBS-T-003 | Error log appears in Axiom | 1. Trigger a deliberate 500 error (e.g., request a non-existent endpoint that causes a server error) 2. Wait 10 seconds 3. In Axiom, query: `\| where level == "error"` | Error log found. No raw stack traces in the log body (stack context goes to Sentry only). |
| OBS-T-004 | Vercel log appears in Axiom | 1. Navigate to `https://app.trendedge.io` 2. Wait 30 seconds 3. In Axiom, query: `\| where isnotnull(vercel.source)` | At least one Vercel log entry found with `vercel.source`, `vercel.path`, `vercel.statusCode` fields |
| OBS-T-005 | Beat log appears in Axiom | 1. Wait for the next Celery Beat tick (every 60 seconds) 2. In Axiom, query: `\| where _railway_service == "trendedge-beat"` | Log entry found from the Beat scheduler |
| OBS-T-006 | Log volume within free tier | 1. In Axiom, navigate to Usage 2. Check daily ingest volume | Daily ingest < 500MB. If exceeded, plan upgrade to Axiom Personal tier. |

### 6.2 Axiom Dashboard Verification

| Test ID | Test Case | Steps | Expected Outcome |
|---|---|---|---|
| OBS-T-010 | All 6 panels render | 1. Open the "TrendEdge Operations" dashboard in Axiom 2. Set time range to "Last 6 hours" | All 6 panels render with non-empty data (assuming the system has been running for at least 1 hour) |
| OBS-T-011 | Request Rate panel groups by status code | 1. View Panel 1 2. Hover over bar segments | Stacked bars show 200, 404, 500 etc. with correct counts |
| OBS-T-012 | Error Rate threshold line visible | 1. View Panel 2 | Red dashed line visible at y=10 |
| OBS-T-013 | p95 Latency threshold line visible | 1. View Panel 3 | Yellow dashed line visible at y=200 |
| OBS-T-014 | Slow Requests table populated | 1. View Panel 4 (requires at least one request > 1s) | Table shows path, duration, request_id for slow requests. If no slow requests exist, table is empty (acceptable). |

### 6.3 Axiom Alerting Verification

| Test ID | Test Case | Steps | Expected Outcome |
|---|---|---|---|
| OBS-T-020 | High Error Rate alert fires | 1. Emit >20 ERROR-level log lines within 5 minutes (e.g., via a test script that makes 25 requests to an endpoint returning 500) 2. Wait for Axiom evaluation cycle (up to 2 minutes) | Email and Telegram notifications received with alert details |
| OBS-T-021 | High Error Rate alert resolves | 1. After OBS-T-020, stop error generation 2. Wait for next evaluation cycle | "Resolved" notification received on both channels |
| OBS-T-022 | Slow API alert fires | 1. Simulate slow API responses (add a temporary `asyncio.sleep(3)` to a test endpoint) 2. Send repeated requests for 10 minutes | Email notification received with p95 latency value |
| OBS-T-023 | Worker Failures alert fires | 1. Cause >5 Celery task failures in 15 minutes (e.g., submit tasks with invalid payloads) | Email and Telegram notifications received |

### 6.4 Uptime Robot Verification

| Test ID | Test Case | Steps | Expected Outcome |
|---|---|---|---|
| OBS-T-030 | All 4 monitors show "Up" status | 1. Open Uptime Robot dashboard 2. View monitor list | All 4 monitors show green "Up" status with response times |
| OBS-T-031 | Downtime alert delivered | 1. Temporarily stop the API service (Railway > Service > Redeploy with intentional failure, or scale to 0 if supported) 2. Wait up to 90 seconds | Email alert received: "TrendEdge API (Liveness) is DOWN" Telegram alert received (for production monitors) |
| OBS-T-032 | Recovery alert delivered | 1. After OBS-T-031, restart the API service 2. Wait up to 120 seconds | Email alert: "TrendEdge API (Liveness) is UP" Telegram alert: "TrendEdge API (Liveness) is UP" |
| OBS-T-033 | Status page reflects downtime | 1. During OBS-T-031 downtime, navigate to `status.trendedge.io` (or Uptime Robot hosted URL) | API component shows "Down" or "Degraded" status |
| OBS-T-034 | Status page reflects recovery | 1. After OBS-T-032 recovery, refresh status page | API component shows "Operational" status |
| OBS-T-035 | Readiness failure with liveness success | 1. Temporarily disable the database (if possible in staging) while keeping the API process running 2. Check Uptime Robot | API Liveness: Up. API Readiness: Down after 2 consecutive failures. |
| OBS-T-036 | Staging monitor uses correct thresholds | 1. Temporarily stop staging API 2. Wait 15+ minutes (3 check cycles at 5-minute intervals) | Alert fires only after 3 consecutive failures (15 minutes), not on first failure |

---

## 7. Failure Modes

### 7.1 Axiom Service Failure

| Scenario | Impact | Mitigation |
|---|---|---|
| Axiom ingest endpoint unavailable | Railway log drain fails silently. Application logs are not lost -- they remain in Railway's own log viewer (7-day retention). Vercel logs continue in Vercel's own log viewer. | Railway automatically retries log drain delivery. Monitor Axiom status at `https://status.axiom.co`. No application impact -- logging continues to stdout regardless. |
| Axiom free tier quota exceeded (>500MB/day) | Axiom stops ingesting new logs for the remainder of the day. Previously ingested logs remain queryable. | Monitor daily usage in Axiom Usage dashboard. If regularly exceeding, upgrade to Personal tier ($25/mo). Reduce log verbosity for high-volume endpoints (e.g., suppress health check request logs). |
| Axiom API token revoked or expired | Log drain returns 401. Railway retries and eventually stops. | Re-generate the token in Axiom and update the Railway log drain configuration. No application code changes needed. |
| Axiom alert notification fails | Alert condition is detected but notification is not delivered. | Both Email and Telegram channels are configured for Critical alerts. If one fails, the other serves as fallback. Check Axiom Monitors > Activity Log for delivery failures. |

### 7.2 Railway Log Drain Failure

| Scenario | Impact | Mitigation |
|---|---|---|
| Railway log drain misconfigured | Logs continue to stdout (application unaffected) but do not reach Axiom. | Verify log drain configuration in Railway dashboard. Test by checking for recent logs in Axiom. Railway provides drain delivery status in the service settings. |
| Railway log drain has high latency (>30s) | Logs arrive in Axiom with delay. Dashboard shows stale data. Alerts may fire late. | Railway log drains are best-effort with no SLA on delivery latency. For time-sensitive monitoring, Uptime Robot provides independent real-time checks that do not depend on log delivery. |

### 7.3 Uptime Robot Failure

| Scenario | Impact | Mitigation |
|---|---|---|
| Uptime Robot service outage | External monitoring stops. No downtime alerts during the outage. | Uptime Robot has its own monitoring and 99.9% SLA. Axiom alerts (High Error Rate, Zero Traffic) provide a secondary layer of failure detection that does not depend on Uptime Robot. |
| Uptime Robot false alarm | Alert fires for a service that is actually up. This can happen due to transient network issues between Uptime Robot's check server and Railway/Vercel. | Alert thresholds of 2-3 consecutive failures mitigate single-check false alarms. The `/health` endpoint returns quickly (<10ms typical) and the 30-second timeout is generous. If false alarms persist, increase the alert threshold to 3 consecutive failures. |
| Telegram bot blocked or rate-limited | Telegram alerts are not delivered. Email alerts continue. | Email is the primary alert channel. Telegram is supplementary. If blocked, re-authorize the Telegram bot. Uptime Robot's Telegram integration handles rate limiting internally. |
| Custom domain DNS propagation delay | `status.trendedge.io` may not resolve immediately after CNAME configuration. | Use the default Uptime Robot hosted URL (`stats.uptimerobot.com/trendedge`) until DNS propagation completes (up to 48 hours). |

### 7.4 Interaction Between Failure Modes

| Combined Scenario | Effect | Recovery |
|---|---|---|
| Axiom down + Uptime Robot down | No centralized logging AND no external monitoring. Application continues to function. Sentry still captures errors. Railway/Vercel dashboards still show recent logs. | Both services recover independently. No data loss for the application. Check Sentry for any errors during the blind spot. |
| API down + Axiom log drain working | Axiom receives the last logs before the process exited. No new logs arrive (process is dead). Uptime Robot detects the downtime. | Uptime Robot alerts operator. Operator checks Axiom for the last logs before crash. Sentry captures the error that caused the crash. |
| Axiom down + high error rate in application | Errors occur but are not visible in Axiom. However, Sentry captures all errors independently. Uptime Robot may detect failures if they manifest as HTTP errors. | Operator sees Sentry alerts. Once Axiom recovers, Railway log drain delivers buffered logs (if Railway buffers them). |

---

## 8. Security Specifications

### 8.1 API Token Management

| Token | Stored In | Access Level | Rotation Policy |
|---|---|---|---|
| Axiom `railway-ingest` token | Railway log drain configuration (encrypted at rest by Railway) | Ingest-only on designated datasets | Rotate every 90 days. Create new token first, update Railway log drains, verify ingestion, then revoke old token. |
| Axiom `dashboard-readonly` token | Axiom dashboard (not shared externally unless read-only link is created) | Query-only on production dataset | Rotate on suspected compromise only. |
| Uptime Robot API key | Uptime Robot account (not used by TrendEdge application) | Uptime Robot account management | Rotate on suspected compromise only. |
| Telegram Bot token | Axiom webhook configuration (for alert delivery) and Uptime Robot Telegram integration | Send messages to operator chat | Rotate on suspected compromise. Revoke via `@BotFather` and create a new bot. |

### 8.2 Least-Privilege Access

- The Axiom ingest token can ONLY write to the designated datasets. It cannot query, delete, or modify data.
- The Axiom dashboard-readonly token can ONLY read from the production dataset. It cannot ingest, modify, or delete.
- Uptime Robot monitors use unauthenticated `GET` requests to public health endpoints. No API keys or tokens are sent from Uptime Robot to TrendEdge. The `/health` and `/health/ready` endpoints are intentionally public. The `/health/detailed` endpoint requires an operator API key and is NOT monitored by Uptime Robot.
- Telegram bot token is never stored in application code, `.env` files, or source control. It is entered directly in the Axiom and Uptime Robot web UIs.

### 8.3 Data Sensitivity

| Data in Axiom | Sensitivity | Notes |
|---|---|---|
| `request_id` | Low | Opaque UUID, no PII |
| `user_id` | Medium | UUID that maps to a user. Stored with 30-day retention. Acceptable for operational debugging. |
| `path` | Low | API endpoint paths, no PII unless path params contain IDs (UUIDs only) |
| `duration_ms` | Low | Performance metric |
| `level`, `logger`, `event` | Low | Operational metadata |
| `status_code`, `method` | Low | HTTP metadata |

The application's logging configuration (in `backend/app/core/logging.py` and enforced in `CLAUDE.md`) explicitly prohibits logging passwords, API keys, JWTs, broker credentials, and credit card numbers. No changes to logging are required for Axiom ingestion.

### 8.4 Axiom Account Security

- Two-factor authentication is required on the Axiom account.
- Account access is limited to the TrendEdge operator. Team member access (if needed later) uses Axiom's built-in RBAC with read-only roles.
- Axiom sessions time out after 30 minutes of inactivity (Axiom default).

### 8.5 Uptime Robot Account Security

- Two-factor authentication is required on the Uptime Robot account.
- The status page displays only uptime/downtime status. It does not expose response bodies, headers, or any application data.
- Monitor URLs (`/health`, `/health/ready`) return minimal information (`{"status":"ok","version":"...","timestamp":"..."}`). No sensitive data is exposed.

---

*This document is FSD-012a of the TrendEdge platform. It specifies the Axiom log shipping and Uptime Robot monitoring integrations required to complete the observability stack defined in PRD-001 and scoped under PRD-012 (CS-1).*
